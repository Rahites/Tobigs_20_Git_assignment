{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73644929, 0.18911926, 0.97708215])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bias          1.000000\n",
       " experience    1.185555\n",
       " salary        0.043974\n",
       " Name: 1, dtype: float64,\n",
       " array([0.73644929, 0.18911926, 0.97708215]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[1], parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "# dot_product 결과 합\n",
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i]*parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1+e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1/(1+np.exp(-z))    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317711380085332"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) = -\\Sigma(y_i log(f(\\hat{y_i})) + (1-y_i) log(1-f(\\hat{y_i}))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    import math\n",
    "    p = logistic(X, parameters)\n",
    "    loss = y * math.log(p) + (1 - y) * math.log(1 - p)\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = dot_product(X, parameters)\n",
    "    loss = (y - y_hat)**2 / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i, :]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss / n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3540504275098055"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)=-\\Sigma(y_i - \\theta^TX_i)X_{ij}$ \n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)=-\\Sigma(y_i - p_i)X_{ij}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X, parameters)\n",
    "        gradient = -(y - y_hat) * X[j]\n",
    "    else:\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = -(y - p) * X[j]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11000022562469841"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Image(\"C:/Users/rhskr/Desktop/배치알고리즘_구현.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i, :]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53.81907356898102, 7.311718945857099, 44.620852577920715]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명: 전체 데이터는 batch_size에 따라 n개로 나누어져 mini-batch로 계싼되는데 이 때 batch_idx는 하나의 mini-batch의 순서를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate/n\n",
    "    \n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73286135, 0.18863181, 0.97410743])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch: 전체 데이터를 학습하는 것  \n",
    "- num_epoch: 전체 데이터를 학습할 횟수\n",
    "<br>\n",
    "\n",
    "BGD: 학습 한번에 모든 데이터 셋을 이용해서 학습   \n",
    "SGD: 학습 한번에 1개에 데이터를 이용해서 학습  \n",
    "MGD: 학습 한번에 여러 데이터를 이용해서 학습  \n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> SGD  \n",
    "batch_size=k -> MGD  \n",
    "batch_size=whole -> BGD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch=1000, tolerance=0.00001, model='logistic', batch_size=16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx, :]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(idx))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(idx))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                print('Early Stopped!!')\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0:  #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.9270416194656861  params: [0.20265408 0.79597408 0.71654034]  gradients: [0.0025037088813350877, 0.001349582156651011, 0.003371788658055676]\n",
      "epoch: 100  loss: 0.7622421383632467  params: [-0.02872847  0.68202525  0.40359393]  gradients: [0.002117896584357611, 0.0009200584322984084, 0.0028733465666155892]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.21797474,  0.61400322,  0.14673616])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train, learning_rate=0.01, num_epoch=200, batch_size=X_train.shape[0])\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.0830966268727054  params: [0.40925746 0.23703029 0.18694517]  gradients: [0.0066411311254585504, 0.0036141099105045323, 0.004672638374883238]\n",
      "epoch: 100  loss: 0.11923218443683131  params: [-1.62799341  3.46402411 -3.30249657]  gradients: [0.001125996816521725, 0.0006127685445311448, 0.000792240935389224]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.78672656,  3.97746832, -3.77972357])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate=0.01, num_epoch=200, batch_size=1)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.2936815062387053  params: [0.76367985 0.74379052 0.58828215]  gradients: [0.003906401684349672, 0.0026720080680908667, 0.005261337037895134]\n",
      "epoch: 100  loss: 0.5650962160272474  params: [-0.39779313  0.62399944 -0.42137918]  gradients: [0.0010860209102988736, 0.0005358091134875544, 0.0022078009125625258]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.77818164,  0.89457708, -0.82745218])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate=0.01, num_epoch=200, batch_size=32)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 22],\n",
       "       [ 3,  7]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40791816, 2.88789961])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.196753094059565  params: [1.32273526 0.95439564]  gradients: [-0.08845840018181776, -0.06542694561003477]\n",
      "epoch: 100  loss: 0.9415812035245991  params: [0.41498875 2.92125953]  gradients: [-0.028011579546215106, -0.018995958364813395]\n",
      "epoch: 200  loss: 0.9415179891824716  params: [0.41368348 2.92360588]  gradients: [-0.027965696842986464, -0.018959507585325365]\n",
      "epoch: 300  loss: 0.9415179107720162  params: [0.41368186 2.92360879]  gradients: [-0.027965639827914675, -0.018959462290613783]\n",
      "epoch: 400  loss: 0.9415179106745813  params: [0.41368186 2.9236088 ]  gradients: [-0.027965639757066216, -0.01895946223432936]\n",
      "epoch: 500  loss: 0.9415179106744604  params: [0.41368186 2.9236088 ]  gradients: [-0.027965639756978265, -0.018959462234259487]\n",
      "epoch: 600  loss: 0.94151791067446  params: [0.41368186 2.9236088 ]  gradients: [-0.027965639756978005, -0.01895946223425928]\n",
      "epoch: 700  loss: 0.94151791067446  params: [0.41368186 2.9236088 ]  gradients: [-0.027965639756978005, -0.01895946223425928]\n",
      "epoch: 800  loss: 0.94151791067446  params: [0.41368186 2.9236088 ]  gradients: [-0.027965639756978005, -0.01895946223425928]\n",
      "epoch: 900  loss: 0.94151791067446  params: [0.41368186 2.9236088 ]  gradients: [-0.027965639756978005, -0.01895946223425928]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.41368186, 2.9236088 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, model='linear')\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
